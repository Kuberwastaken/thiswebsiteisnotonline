# OpenRouter API
OPENROUTER_API_KEY=your_openrouter_api_key_here

# (Optional) Local Model Configuration
# To run a local GPT-OSS 20B (via vLLM, Transformers serve, Ollama, etc.) configure these:
# MODEL_PROVIDER can be: openrouter | local
# If 'local', the app will send OpenAI-compatible chat requests to MODEL_API_BASE
# MODEL_API_BASE example for vLLM: http://localhost:8000/v1
# MODEL_API_BASE example for Transformers serve: http://localhost:8000/v1
# MODEL_API_BASE example for Ollama OpenAI compatible (after enabling): http://localhost:11434/v1
# MODEL_NAME example: openai/gpt-oss-20b  (for vLLM / Transformers)
# MODEL_NAME example (Ollama): gpt-oss:20b
# MODEL_API_KEY: only needed if your local server enforces auth (leave blank otherwise)
MODEL_PROVIDER=openrouter
MODEL_API_BASE=
MODEL_NAME=
MODEL_API_KEY=

# Site Information (for OpenRouter rankings)
SITE_URL=https://thiswebsiteisnot.online
SITE_NAME=This Website is Not Online

# Supabase Configuration
SUPABASE_URL=
SUPABASE_ANON_KEY=
SUPABASE_SERVICE_KEY=

# Environment
NODE_ENV=production
